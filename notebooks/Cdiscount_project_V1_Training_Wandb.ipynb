{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to mount google drive in case you are loading the data from your google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "%cd /gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "data_path = '/gdrive/MyDrive/AppliedAI_ThesisProj/dataset'\n",
    "os.chdir(data_path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, math, io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing as mp\n",
    "import bson\n",
    "import struct\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "import keras\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "# Check on Keras Preprocessing\n",
    "#from keras_preprocessing import image\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import *\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../cdiscount-image-classification-challenge\"]).decode(\"utf8\"))\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../cdiscount-image-classification-challenge\"\n",
    "\n",
    "train_bson_path = os.path.join(data_dir, \"train.bson\")\n",
    "num_train_products = 7069896\n",
    "\n",
    "# train_bson_path = os.path.join(data_dir, \"train_example.bson\")\n",
    "# num_train_products = 82\n",
    "\n",
    "test_bson_path = os.path.join(data_dir, \"test.bson\")\n",
    "num_test_products = 1768182"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The generator uses several lookup tables that describe the layout of the BSON file, which products and images are part of the training/validation sets, and so on.\n",
    "\n",
    "#You only need to generate these tables once, as they get saved to CSV files.\n",
    "\n",
    "#Lookup table for categories\n",
    "categories_path = os.path.join(data_dir, \"category_names.csv\")\n",
    "categories_df = pd.read_csv(categories_path, index_col=\"category_id\")\n",
    "\n",
    "# Maps the category_id to an integer index. This is what we'll use to\n",
    "# one-hot encode the labels.\n",
    "categories_df[\"category_idx\"] = pd.Series(range(len(categories_df)), index=categories_df.index)\n",
    "\n",
    "categories_df.to_csv(\"categories.csv\")\n",
    "categories_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionaries for quick lookup of category_id to category_idx mapping.\n",
    "def make_category_tables():\n",
    "    cat2idx = {}\n",
    "    idx2cat = {}\n",
    "    i=0\n",
    "    for ir in categories_df.itertuples():\n",
    "            \n",
    "        category_id = ir[0]\n",
    "        category_idx = ir[4]\n",
    "        cat2idx[category_id] = category_idx\n",
    "        idx2cat[category_idx] = category_id\n",
    "      \n",
    "    return cat2idx, idx2cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat2idx, idx2cat = make_category_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if it works:\n",
    "cat2idx[1000012755], idx2cat[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this takes a few minutes to execute, but we only have to do it once (we'll save the table to a CSV file afterwards).\n",
    "def read_bson(bson_path, num_records, with_categories):\n",
    "    rows = {}\n",
    "    with open(bson_path, \"rb\") as f, tqdm(total=num_records) as pbar:\n",
    "        offset = 0\n",
    "        while True:\n",
    "            item_length_bytes = f.read(4)\n",
    "            if len(item_length_bytes) == 0:\n",
    "                break\n",
    "\n",
    "            length = struct.unpack(\"<i\", item_length_bytes)[0]\n",
    "\n",
    "            f.seek(offset)\n",
    "            item_data = f.read(length)\n",
    "            assert len(item_data) == length\n",
    "\n",
    "            item = bson.BSON.decode(item_data)\n",
    "            product_id = item[\"_id\"]\n",
    "            num_imgs = len(item[\"imgs\"])\n",
    "\n",
    "            row = [num_imgs, offset, length]\n",
    "            if with_categories:\n",
    "                row += [item[\"category_id\"]]\n",
    "            rows[product_id] = row\n",
    "\n",
    "            offset += length\n",
    "            f.seek(offset)\n",
    "            pbar.update()\n",
    "\n",
    "    columns = [\"num_imgs\", \"offset\", \"length\"]\n",
    "    if with_categories:\n",
    "        columns += [\"category_id\"]\n",
    "\n",
    "    df = pd.DataFrame.from_dict(rows, orient=\"index\")\n",
    "    df.index.name = \"product_id\"\n",
    "    df.columns = columns\n",
    "    df.sort_index(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time train_offsets_df = read_bson(train_bson_path, num_records=num_train_products, with_categories=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_offsets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_offsets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_offsets_df['category_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_offsets_df['num_imgs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_offsets_df.to_csv(\"train_offsets.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a random train/validation split\n",
    "We split on products, not on individual images. Since some of the categories only have a few products, we do the split separately for each category.\n",
    "\n",
    "This creates two new tables, one for the training images and one for the validation images. There is a row for every single image, so if a product has more than one image it occurs more than once in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_val_set(df, split_percentage=0.2, drop_percentage=0.):\n",
    "    # Find the product_ids for each category.\n",
    "    category_dict = defaultdict(list)\n",
    "    for ir in tqdm(df.itertuples()):\n",
    "        category_dict[ir[4]].append(ir[0])\n",
    "\n",
    "    train_list = []\n",
    "    val_list = []\n",
    "    with tqdm(total=len(df)) as pbar:\n",
    "        for category_id, product_ids in category_dict.items():\n",
    "            category_idx = cat2idx[category_id]\n",
    "\n",
    "            # Randomly remove products to make the dataset smaller.\n",
    "            keep_size = int(len(product_ids) * (1. - drop_percentage))\n",
    "            if keep_size < len(product_ids):\n",
    "                product_ids = np.random.choice(product_ids, keep_size, replace=False)\n",
    "\n",
    "            # Randomly choose the products that become part of the validation set.\n",
    "            val_size = int(len(product_ids) * split_percentage)\n",
    "            if val_size > 0:\n",
    "                val_ids = np.random.choice(product_ids, val_size, replace=False)\n",
    "            else:\n",
    "                val_ids = []\n",
    "\n",
    "            # Create a new row for each image.\n",
    "            for product_id in product_ids:\n",
    "                row = [product_id, category_idx]\n",
    "                for img_idx in range(df.loc[product_id, \"num_imgs\"]):\n",
    "                    if product_id in val_ids:\n",
    "                        val_list.append(row + [img_idx])\n",
    "                    else:\n",
    "                        train_list.append(row + [img_idx])\n",
    "                pbar.update()\n",
    "                \n",
    "    columns = [\"product_id\", \"category_idx\", \"img_idx\"]\n",
    "    train_df = pd.DataFrame(train_list, columns=columns)\n",
    "    val_df = pd.DataFrame(val_list, columns=columns)   \n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_df, val_images_df = make_val_set(train_offsets_df, split_percentage=0.2, \n",
    "                                              drop_percentage=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training images:\", len(train_images_df))\n",
    "print(\"Number of validation images:\", len(val_images_df))\n",
    "print(\"Total images:\", len(train_images_df) + len(val_images_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_images_df[\"category_idx\"].unique()), len(val_images_df[\"category_idx\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_df.to_csv(\"train_images.csv\")\n",
    "val_images_df.to_csv(\"val_images.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: The generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First load the lookup tables from the CSV files (you don't need to do this if you just did all the steps from part 1).\n",
    "\n",
    "categories_df = pd.read_csv(\"categories.csv\", index_col=0)\n",
    "# cat2idx, idx2cat = make_category_tables()\n",
    "\n",
    "train_offsets_df = pd.read_csv(\"train_offsets.csv\", index_col=0)\n",
    "train_images_df = pd.read_csv(\"train_images.csv\", index_col=0)\n",
    "val_images_df = pd.read_csv(\"val_images.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import Iterator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from PIL import Image\n",
    "from pymongo import MongoClient\n",
    "import io\n",
    "import pymongo\n",
    "import skimage.io as skio\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "client = MongoClient(connect= False)\n",
    "train = client.Cdiscount['train']\n",
    "test = client.Cdiscount['test']\n",
    "\n",
    "\n",
    "class BSONIterator(Iterator):\n",
    "    def __init__(self, bson_file, images_df, offsets_df, num_class,\n",
    "                 image_data_generator, lock, target_size=(180, 180), \n",
    "                 with_labels=True, batch_size=32, shuffle=False, seed=None):\n",
    "\n",
    "        self.file = bson_file\n",
    "        self.images_df = images_df\n",
    "        self.offsets_df = offsets_df\n",
    "        self.with_labels = with_labels\n",
    "        self.samples = len(images_df)\n",
    "        self.num_class = num_class\n",
    "        self.image_data_generator = image_data_generator\n",
    "        self.target_size = tuple(target_size)\n",
    "        self.image_shape = self.target_size + (3,)\n",
    "\n",
    "        print(\"Found %d images belonging to %d classes.\" % (self.samples, self.num_class))\n",
    "\n",
    "        super(BSONIterator, self).__init__(self.samples, batch_size, shuffle, seed)\n",
    "        self.lock = lock\n",
    "\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        batch_x = np.zeros((len(index_array),) + self.image_shape, dtype=K.floatx())\n",
    "        if self.with_labels:\n",
    "            batch_y = np.zeros((len(batch_x), self.num_class), dtype=K.floatx())\n",
    "\n",
    "        for i, j in enumerate(index_array):\n",
    "            # Protect file and dataframe access with a lock.\n",
    "            with self.lock:\n",
    "                image_row = self.images_df.iloc[j]\n",
    "                product_id = image_row[\"product_id\"] \n",
    "                offset_row = self.offsets_df.loc[product_id]\n",
    "\n",
    "                # Read this product's data from the BSON file.\n",
    "                self.file.seek(offset_row[\"offset\"])\n",
    "                item_data = self.file.read(offset_row[\"length\"])\n",
    "\n",
    "                \n",
    "            # Grab the image from the product.\n",
    "            #print(j)\n",
    "            #img_idx =0\n",
    "            item = bson.BSON.decode(item_data)\n",
    "            #item = train.find_one({'_id':int(j)})\n",
    "            #print(item)\n",
    "            img_idx = image_row[\"img_idx\"]\n",
    "            #print(img_idx)\n",
    "            bson_img = item[\"imgs\"][img_idx][\"picture\"]\n",
    "\n",
    "            img = Image.open(io.BytesIO(bson_img))\n",
    "            img = img.convert('RGB')\n",
    "            img = img.resize(self.target_size, Image.NEAREST)\n",
    "            # Preprocess the image.\n",
    "            x = img_to_array(img)\n",
    "            x = self.image_data_generator.random_transform(x)\n",
    "            x = self.image_data_generator.standardize(x)\n",
    "\n",
    "            # Add the image and the label to the batch (one-hot encoded).\n",
    "            batch_x[i] = x\n",
    "            if self.with_labels:\n",
    "                batch_y[i, image_row[\"category_idx\"]] = 1\n",
    "\n",
    "        if self.with_labels:\n",
    "            return batch_x, batch_y\n",
    "        else:\n",
    "            return batch_x\n",
    "\n",
    "    def next(self):\n",
    "        with self.lock:\n",
    "            index_array = next(self.index_generator)\n",
    "        #print(index_array)\n",
    "        return self._get_batches_of_transformed_samples(index_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bson_file = open(train_bson_path, \"rb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create a generator for training and a generator for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because the training and validation generators read from the same BSON file, they need to use the same lock to protect it.\n",
    "import threading\n",
    "lock = threading.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5270\n",
    "num_train_images = len(train_images_df)\n",
    "num_val_images = len(val_images_df)\n",
    "batch_size = 128\n",
    "target_size = (180,180)\n",
    "# Tip: use ImageDataGenerator for data augmentation and preprocessing.\n",
    "train_datagen = ImageDataGenerator()\n",
    "train_gen = BSONIterator(train_bson_file, train_images_df, train_offsets_df, \n",
    "                         num_classes, train_datagen, lock,target_size = target_size,\n",
    "                         batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "val_gen = BSONIterator(train_bson_file, val_images_df, train_offsets_df,\n",
    "                       num_classes, val_datagen, lock,target_size = target_size,\n",
    "                       batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next(train_gen)  # warm-up\n",
    "\n",
    "%time bx, by = next(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time bx, by = next(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bx[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(bx[4].astype(np.uint8))\n",
    "\n",
    "print(\"ClassID_OneHotencoded:{}\".format(by))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wandb Loggers\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.init(project=\"cdiscount-challenge-diploma-project\", entity=\"udaygirish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TF Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_exception(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape = input_shape)\n",
    "    x = inputs\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    activation = \"softmax\"\n",
    "    units = num_classes\n",
    "    \n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(units, activation= activation)(x)\n",
    "    return keras.Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model_exception(input_shape = (180,180,3), num_classes = 5270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "base_learning_rate = 1e-2\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=base_learning_rate,\n",
    "    decay_steps=20000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "wandb.config = {\n",
    " \"learning_rate\" : base_learning_rate,\n",
    " \"epochs\" : epochs,\n",
    " \"batch_size\" : 128\n",
    "}\n",
    "filepath = \"./weights.best_exception_{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint_f = keras.callbacks.ModelCheckpoint(filepath,monitor = \"val_accuracy\", verbose=1, save_best_only=False, mode=\"max\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"), checkpoint_f, WandbCallback()\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate = base_learning_rate),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\", precision_m, recall_m, f1_m],\n",
    ")\n",
    "H = model.fit(\n",
    "    train_gen, epochs=epochs, callbacks=callbacks, validation_data=val_gen,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_resnet101_mod(input_shape, num_classes):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    #base_model = tf.keras.applications.resnet.ResNet101(include_top=False, weights = \"imagenet\", input_shape = input_shape)\n",
    "    base_model = tf.keras.applications.ResNet101V2(include_top=False, weights = None, input_shape = input_shape)\n",
    "    x = inputs\n",
    "    x = base_model(x)\n",
    "    #print(x.shape)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    global_avg_layer = layers.GlobalAveragePooling2D()\n",
    "    #x = global_avg_layer(x)\n",
    "#     x = layers.Dropout(0.3)(x)\n",
    "#     x = layers.Conv2D(1024, 1, activation='relu')(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Conv2D(256, 1, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    #x = layers.Dropout(0.1)(x)\n",
    "    outputs = layers.Dense(num_classes, activation= \"softmax\")(x)\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-5]:\n",
    "        layer.trainable=False\n",
    "    return tf.keras.Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model_resnet101_mod(input_shape=(180,180,3) , num_classes= 5270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "base_learning_rate = 1e-3\n",
    "INIT_LR = 1e-4\n",
    "MAX_LR = 1e-3\n",
    "lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=base_learning_rate,\n",
    "    decay_steps=50000,\n",
    "    end_learning_rate = 1e-4,\n",
    "    power=0.5)\n",
    "\n",
    "steps_per_epoch = 7730\n",
    "cyclic_lr_schedule = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\n",
    "    maximal_learning_rate= MAX_LR,\n",
    "    scale_fn=lambda x: 1/(2.**(x-1)),\n",
    "    step_size= 2\n",
    ")\n",
    "\n",
    "wandb.config = {\n",
    " \"learning_rate\" : lr_schedule,\n",
    " \"epochs\" : epochs,\n",
    " \"batch_size\" : 128\n",
    "}\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.2,\n",
    "                              patience=5, min_lr=1e-4)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate =  lr_schedule)\n",
    "class LRLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, optimizer):\n",
    "        super(LRLogger, self).__init__\n",
    "        self.optimizer =optimizer\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs):\n",
    "        lr = self.optimizer.learning_rate(epoch)\n",
    "        wandb.log({\"lr\":lr}, commit = False)\n",
    "        \n",
    "        \n",
    "filepath = \"./weights.best_{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint_f = keras.callbacks.ModelCheckpoint(filepath,monitor = \"val_accuracy\", verbose=1, save_best_only=False, mode=\"max\")\n",
    "\n",
    "callbacks = [\n",
    "    checkpoint_f,WandbCallback()\n",
    ", LRLogger(optimizer) , reduce_lr]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    #using Focal cross entropy loss\n",
    "    #loss = tfa.losses.SigmoidFocalCrossEntropy(),\n",
    "    metrics=[\"accuracy\", precision_m, recall_m, f1_m],\n",
    ")\n",
    "\n",
    "H = model.fit(\n",
    "    train_gen, epochs=epochs, callbacks=callbacks, validation_data=val_gen,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_inceptionv3(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape = input_shape)\n",
    "    base_model  = tf.keras.applications.InceptionV3(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n",
    "    #base_model = tf.keras.applications.InceptionV3(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    x = base_model(inputs)\n",
    "    global_avg_layer = layers.GlobalAveragePooling2D()\n",
    "    x = global_avg_layer(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Dense(num_classes, activation= \"softmax\")(x)\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-5]:\n",
    "        layer.trainable = False      # Train all layers - From Scratch\n",
    "    return keras.Model(inputs,outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_inceptionv3_mod(input_shape, num_classes):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    base_model = tf.keras.applications.InceptionV3(include_top=False, weights = None, input_shape = input_shape)\n",
    "    x = inputs\n",
    "    x = base_model(x)\n",
    "    #print(x.shape)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    global_avg_layer = layers.GlobalAveragePooling2D()\n",
    "    #x = global_avg_layer(x)\n",
    "    #x = layers.Flatten()(x)\n",
    "    x = layers.Conv2D(512, 1, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(num_classes, activation= \"softmax\")(x)\n",
    "    base_model.trainable = True\n",
    "#     for layer in base_model.layers[:-20]:\n",
    "#         layer.trainable=False\n",
    "    return tf.keras.Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.InceptionV3(include_top=False, weights = \"imagenet\", input_shape = (180,180,3))\n",
    "#base_model.summary(line_length =100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = make_model_inceptionv3_mod(input_shape = (180,180,3), num_classes = 5270)\n",
    "#model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model_inceptionv3_mod(input_shape = (180,180,3), num_classes = 5270)\n",
    "#model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1934.0 batches). You may need to use the repeat() function when building your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.plot_model(model, show_shapes=True)\n",
    "# Inception - V3 --> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "epochs = 100\n",
    "base_learning_rate = 1e-3\n",
    "INIT_LR = 1e-4\n",
    "MAX_LR = 1e-3\n",
    "lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=base_learning_rate,\n",
    "    decay_steps=50000,\n",
    "    end_learning_rate = 1e-4,\n",
    "    power=0.5)\n",
    "\n",
    "steps_per_epoch = 7730\n",
    "cyclic_lr_schedule = tfa.optimizers.CyclicalLearningRate(initial_learning_rate=INIT_LR,\n",
    "    maximal_learning_rate= MAX_LR,\n",
    "    scale_fn=lambda x: 1/(2.**(x-1)),\n",
    "    step_size= 2\n",
    ")\n",
    "\n",
    "# cyclic_exp_lr_schedule = tfa.optimizers.ExponentialCyclicalLearningRate(\n",
    "#     initial_learning_rate: Union[FloatTensorLike, Callable],\n",
    "#     maximal_learning_rate: Union[FloatTensorLike, Callable],\n",
    "#     step_size: tfa.types.FloatTensorLike,\n",
    "#     scale_mode: str = 'iterations',\n",
    "#     gamma: tfa.types.FloatTensorLike = 1.0,\n",
    "#     name: str = 'ExponentialCyclicalLearningRate'\n",
    "# )\n",
    "\n",
    "\n",
    "wandb.config = {\n",
    " \"learning_rate\" : cyclic_lr_schedule,\n",
    " \"epochs\" : epochs,\n",
    " \"batch_size\" : 128\n",
    "}\n",
    "\n",
    "# reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.2,\n",
    "#                               patience=3, min_lr=1e-4)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = cyclic_lr_schedule)\n",
    "class LRLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, optimizer):\n",
    "        super(LRLogger, self).__init__\n",
    "        self.optimizer =optimizer\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs):\n",
    "        lr = self.optimizer.learning_rate(epoch)\n",
    "        wandb.log({\"lr\":lr}, commit = False)\n",
    "        \n",
    "        \n",
    "filepath = \"./weights.best_{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint_f = keras.callbacks.ModelCheckpoint(filepath,monitor = \"val_accuracy\", verbose=1, save_best_only=False, mode=\"max\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"inception_v3_training/save_at_{epoch}.h5\"), checkpoint_f,WandbCallback()\n",
    ", LRLogger(optimizer) ] #,reduce_lr ]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"categorical_crossentropy\", \n",
    "    #using Focal cross entropy loss\n",
    "    #loss = tfa.losses.SigmoidFocalCrossEntropy(),\n",
    "    metrics=[\"accuracy\", precision_m, recall_m, f1_m],\n",
    ")\n",
    "\n",
    "H = model.fit(\n",
    "    train_gen, epochs=epochs, callbacks=callbacks, validation_data=val_gen,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient Net B7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_effnet_b7_1(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape = input_shape)\n",
    "    base_model  = tf.keras.applications.EfficientNetB7(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    x = base_model(inputs)\n",
    "    global_avg_layer = layers.GlobalAveragePooling2D()\n",
    "    x = global_avg_layer(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "#     x = layers.Conv2D(256, 1, activation='relu')(x)\n",
    "#     x = layers.BatchNormalization()(x)\n",
    "#     x = layers.Dropout(0.3)(x)\n",
    "#     x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(num_classes, activation= \"softmax\")(x)\n",
    "    base_model.trainable = False\n",
    "    for layer in base_model.layers[:-5]:\n",
    "        layer.trainable = False\n",
    "    return keras.Model(inputs,outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_effnet_b7(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape = input_shape)\n",
    "    base_model  = tf.keras.applications.EfficientNetB7(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    x = base_model(inputs)\n",
    "    global_avg_layer = layers.GlobalAveragePooling2D()\n",
    "#     x = global_avg_layer(x)\n",
    "#     x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Conv2D(256, 1, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(num_classes, activation= \"softmax\")(x)\n",
    "    base_model.trainable = False\n",
    "    for layer in base_model.layers[:-5]:\n",
    "        layer.trainable = False\n",
    "    return keras.Model(inputs,outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model_effnet_b7(input_shape = (180,180,3), num_classes = 5270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step Decay \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cyclical learning rate Approach\n",
    "## --> Implement this later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "base_learning_rate = 1e-3\n",
    "lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=base_learning_rate,\n",
    "    decay_steps=80000,\n",
    "    end_learning_rate = 1e-4,\n",
    "    power=0.5)\n",
    "\n",
    "\n",
    "\n",
    "wandb.config = {\n",
    " \"learning_rate\" : lr_schedule,\n",
    " \"epochs\" : epochs,\n",
    " \"batch_size\" : 128\n",
    "}\n",
    "\n",
    "earlystopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.2,\n",
    "                              patience=5, min_lr=1e-4)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = lr_schedule)\n",
    "class LRLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, optimizer):\n",
    "        super(LRLogger, self).__init__\n",
    "        self.optimizer =optimizer\n",
    "    \n",
    "    def on_epoch_end(self,epoch,logs):\n",
    "        lr = self.optimizer.learning_rate(epoch)\n",
    "        wandb.log({\"lr\":lr}, commit = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"./efficientnet_b7_training/weights.best_effnet_b7{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint_f = keras.callbacks.ModelCheckpoint(filepath,monitor = \"val_accuracy\", verbose=1, save_best_only=False, mode=\"max\")\n",
    "\n",
    "callbacks = [checkpoint_f,WandbCallback()\n",
    ", LRLogger(optimizer)]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\", precision_m, recall_m, f1_m],\n",
    ")\n",
    "H = model.fit(\n",
    "    train_gen, epochs=epochs, callbacks=callbacks, validation_data=val_gen,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAS Net  - Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_nasnet_large(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape = input_shape)\n",
    "    base_model  = tensorflow.keras.applications.nasnet.NASNetLarge(weights=\"imagenet\", include_top=False)\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    x = base_model(inputs)\n",
    "    global_avg_layer = layers.GlobalAveragePooling2D()\n",
    "    x = global_avg_layer(x)\n",
    "    #x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Dense(num_classes, activation= \"softmax\")(x)\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-10]:\n",
    "        layer.trainable = False\n",
    "    return keras.Model(inputs,outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5270\n",
    "num_train_images = len(train_images_df)\n",
    "num_val_images = len(val_images_df)\n",
    "batch_size = 128\n",
    "\n",
    "# Tip: use ImageDataGenerator for data augmentation and preprocessing.\n",
    "train_datagen = ImageDataGenerator()\n",
    "train_gen_mod = BSONIterator(train_bson_file, train_images_df, train_offsets_df, \n",
    "                         num_classes, train_datagen, lock,target_size=(331,331),\n",
    "                         batch_size=batch_size, shuffle=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "val_gen_mod = BSONIterator(train_bson_file, val_images_df, train_offsets_df,\n",
    "                       num_classes, val_datagen, lock,target_size=(331,331),\n",
    "                       batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model_nasnet_large(input_shape = (331,331,3), num_classes = 5270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "base_learning_rate = 1e-2\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=base_learning_rate,\n",
    "    decay_steps=20000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "wandb.config = {\n",
    " \"learning_rate\" : base_learning_rate,\n",
    " \"epochs\" : epochs,\n",
    " \"batch_size\" : 128\n",
    "}\n",
    "\n",
    "filepath = \"./weights.best_nasnet_b7{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint_f = keras.callbacks.ModelCheckpoint(filepath,monitor = \"val_accuracy\", verbose=1, save_best_only=False, mode=\"max\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"), checkpoint_f, WandbCallback()\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate = base_learning_rate),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\", precision_m, recall_m, f1_m],\n",
    ")\n",
    "H = model.fit(\n",
    "    train_gen_mod, epochs=epochs, callbacks=callbacks, validation_data=val_gen_mod,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient Net V2-S - Under Exploration - NAS Type Model\n",
    "### Keras nightly build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install effnetv2_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_efficientv2_s(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape = input_shape)\n",
    "    hub_url= \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_s/feature_vector/2\"\n",
    "    base_model = hub.KerasLayer(hub_url, trainable=False)\n",
    "#     base_model.trainable = True\n",
    "    \n",
    "    x = base_model(inputs)\n",
    "    global_avg_layer = layers.GlobalAveragePooling2D()\n",
    "    x = global_avg_layer(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    outputs = layers.Dense(num_classes, activation= \"softmax\")(x)\n",
    "#     for layer in base_model.layers[:-15]:\n",
    "#         layer.trainable = False\n",
    "    return keras.Model(inputs,outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tensorflow Version:{}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model_efficientv2_s(input_shape = (180,180,3), num_classes = 5270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "base_learning_rate = 4e-3\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=base_learning_rate,\n",
    "    decay_steps=20000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "wandb.config = {\n",
    " \"learning_rate\" : base_learning_rate,\n",
    " \"epochs\" : epochs,\n",
    " \"batch_size\" : 128\n",
    "}\n",
    "\n",
    "\n",
    "filepath = \"./weights.best_effnetv2s_{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint_f = keras.callbacks.ModelCheckpoint(filepath,monitor = \"val_accuracy\", verbose=1, save_best_only=False, mode=\"max\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"), checkpoint_f, WandbCallback()\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate = base_learning_rate),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\", precision_m, recall_m, f1_m],\n",
    ")\n",
    "model.fit(\n",
    "    train_gen, epochs=epochs, callbacks=callbacks, validation_data=val_gen,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of Cdiscount_project_V1_Training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
